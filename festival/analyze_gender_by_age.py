#!/usr/bin/env python
# coding: utf-8

# In[ ]:


import streamlit as st
import pandas as pd
import os
from openai import OpenAI

client = OpenAI(api_key=st.secrets["OPENAI_API_KEY"])

# âœ… ì‹œì‚¬ì  ì˜ˆì‹œ ë¶ˆëŸ¬ì˜¤ê¸°
def load_insight_examples(section_id):
    try:
        path = os.path.join("press_release_app", "data", "insights", f"{section_id}.txt")
        with open(path, "r", encoding="utf-8") as f:
            return f.read()
    except FileNotFoundError:
        return ""

# âœ… 6ë²ˆ ë¶„ì„ê¸°: ì—°ë ¹ë³„ ì„±ë³„ ë°©ë¬¸ê° ë¶„ì„
def analyze_gender_by_age():
    st.subheader("ğŸ“Š 6. ì—°ë ¹ë³„ ì„±ë³„ ë°©ë¬¸ê° ë¶„ì„")

    uploaded_file = st.file_uploader("ğŸ“‚ ì—°ë ¹ë³„ ì„±ë³„ ë°©ë¬¸ê° ì—‘ì…€ ì—…ë¡œë“œ", type=["xlsx"])
    if not uploaded_file:
        return

    # âœ… ì—‘ì…€ ë¡œë”©
    try:
        df = pd.read_excel(uploaded_file)
    except Exception:
        st.error("âŒ ì—‘ì…€ íŒŒì¼ì„ ë¶ˆëŸ¬ì˜¤ëŠ” ë° ë¬¸ì œê°€ ë°œìƒí–ˆìŠµë‹ˆë‹¤.")
        return

    # âœ… í•„ìˆ˜ ì»¬ëŸ¼ í™•ì¸
    required_cols = {"ì—°ë ¹ëŒ€", "êµ¬ë¶„", "ë‚¨ì„±", "ì—¬ì„±"}
    if not required_cols.issubset(df.columns):
        st.error("âŒ ì—‘ì…€ íŒŒì¼ì— 'ì—°ë ¹ëŒ€', 'êµ¬ë¶„', 'ë‚¨ì„±', 'ì—¬ì„±' ì»¬ëŸ¼ì´ í•„ìš”í•©ë‹ˆë‹¤.")
        return

    # âœ… ìˆ˜ì¹˜ ì •ì œ
    df["ë‚¨ì„±"] = df["ë‚¨ì„±"].apply(lambda x: int(str(x).replace(",", "")) if pd.notnull(x) else 0)
    df["ì—¬ì„±"] = df["ì—¬ì„±"].apply(lambda x: int(str(x).replace(",", "")) if pd.notnull(x) else 0)

    # âœ… ì—°ë ¹ëŒ€ë³„ ì„±ë³„ í•©ì‚°
    grouped = df.groupby("ì—°ë ¹ëŒ€")[["ë‚¨ì„±", "ì—¬ì„±"]].sum().reset_index()

    # âœ… ì „ì²´ í•©ì‚°
    total_male = grouped["ë‚¨ì„±"].sum()
    total_female = grouped["ì—¬ì„±"].sum()

    # âœ… ë¹„ìœ¨ ê³„ì‚°
    grouped["ë‚¨ìë¹„ìœ¨"] = (grouped["ë‚¨ì„±"] / total_male * 100).round(2)
    grouped["ì—¬ìë¹„ìœ¨"] = (grouped["ì—¬ì„±"] / total_female * 100).round(2)

    st.dataframe(grouped, use_container_width=True)

    # âœ… GPT ì‹œì‚¬ì  ìƒì„±
    with st.spinner("ğŸ¤– GPT ì‹œì‚¬ì  ìƒì„± ì¤‘..."):
        name = st.session_state.get("festival_name", "ë³¸ ì¶•ì œ")
        period = st.session_state.get("festival_period", "")
        location = st.session_state.get("festival_location", "")
        #reference = load_insight_examples("6_gender")

        summary = "\n".join([
            f"- {row['ì—°ë ¹ëŒ€']}: ë‚¨ì„± {row['ë‚¨ì„±']:,}ëª… / ì—¬ì„± {row['ì—¬ì„±']:,}ëª…"
            for _, row in grouped.iterrows()
        ])

        prompt = f"""ë‹¤ìŒì€ {name}({period}, {location}) ì¶•ì œì˜ ì—°ë ¹ë³„ ì„±ë³„ ë°©ë¬¸ê° ë¶„ì„ì…ë‹ˆë‹¤.

[ì—°ë ¹ëŒ€ë³„ ì„±ë³„ ë°©ë¬¸ê° ìˆ˜ ìš”ì•½]
{summary}

[ì°¸ê³ ìë£Œ]
{reference}

ìœ„ ë°ì´í„°ë¥¼ ë°”íƒ•ìœ¼ë¡œ, ì—°ë ¹ëŒ€ë³„ ë‚¨ë…€ ë°©ë¬¸ìì˜ íŠ¹ì§•ê³¼ ì‹œì‚¬ì ì„ 3~5ë¬¸ì¥ìœ¼ë¡œ ê°„ê²°íˆ ì‘ì„±í•´ì£¼ì„¸ìš”.
"""

        response = client.chat.completions.create(
            model="gpt-4o",
            messages=[
                {"role": "system", "content": "ë„ˆëŠ” ì§€ë°©ì •ë¶€ ì¶•ì œ ë°ì´í„°ë¥¼ ë¶„ì„í•˜ëŠ” ì „ë¬¸ê°€ì•¼."},
                {"role": "user", "content": prompt}
            ],
            temperature=0.5,
            max_tokens=700
        )

        st.subheader("ğŸ§  GPT ì‹œì‚¬ì ")
        st.write(response.choices[0].message.content)

