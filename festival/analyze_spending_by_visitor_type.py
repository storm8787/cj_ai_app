#!/usr/bin/env python
# coding: utf-8

# In[ ]:


import streamlit as st
import pandas as pd
import os
from openai import OpenAI

client = OpenAI(api_key=st.secrets["OPENAI_API_KEY"])

# âœ… ì‹œì‚¬ì  ì˜ˆì‹œ ë¶ˆëŸ¬ì˜¤ê¸°
def load_insight_examples(section_id):
    try:
        path = os.path.join("press_release_app", "data", "insights", f"{section_id}.txt")
        with open(path, "r", encoding="utf-8") as f:
            return f.read()
    except FileNotFoundError:
        return ""

def analyze_spending_by_visitor_type():
    st.subheader("ğŸ“Š 10. ë°©ë¬¸ìœ í˜•ë³„ ì†Œë¹„í˜„í™© ë¶„ì„ê¸°")

    st.markdown("ğŸ« **8ë²ˆ ë¶„ì„ ê²°ê³¼ì—ì„œ ë„ì¶œëœ ì „ì²´ ì†Œë¹„ê¸ˆì•¡ê³¼ ê±´ìˆ˜ë¥¼ ì…ë ¥í•˜ê³ , ìœ í˜•ë³„ ë¹„ìœ¨ì„ ì…ë ¥í•˜ì„¸ìš”**")

    total_amount = st.number_input("ğŸ’° ì „ì²´ ì†Œë¹„ê¸ˆì•¡ (ì²œì›)", min_value=0, step=1000, key="type_total_amount")
    total_count = st.number_input("ğŸ§¾ ì „ì²´ ì†Œë¹„ê±´ìˆ˜ (ê±´)", min_value=0, step=1, key="type_total_count")

    col1, col2 = st.columns(2)
    with col1:
        local_ratio_amt = st.number_input("ğŸ  í˜„ì§€ì¸ ì†Œë¹„ê¸ˆì•¡ ë¹„ìœ¨ (%)", min_value=0.0, max_value=100.0, step=0.1)
    with col2:
        local_ratio_cnt = st.number_input("ğŸ  í˜„ì§€ì¸ ì†Œë¹„ê±´ìˆ˜ ë¹„ìœ¨ (%)", min_value=0.0, max_value=100.0, step=0.1)

    if st.button("ğŸ“Š ë¶„ì„ ì‹¤í–‰", key="btn_type_analysis"):
        # ì—­ì‚°
        local_amount = int(total_amount * local_ratio_amt / 100)
        tourist_amount = total_amount - local_amount

        local_count = int(total_count * local_ratio_cnt / 100)
        tourist_count = total_count - local_count

        # ë‹¨ê°€ ê³„ì‚°
        local_unit = int(local_amount * 1000 / local_count) if local_count else 0
        tourist_unit = int(tourist_amount * 1000 / tourist_count) if tourist_count else 0
        total_unit = int(total_amount * 1000 / total_count) if total_count else 0

        # ë¹„ìœ¨ ë¬¸ìì—´
        local_amt_str = f"{local_amount:,}ì²œì› ({local_ratio_amt:.2f}%)"
        tourist_amt_str = f"{tourist_amount:,}ì²œì› ({100 - local_ratio_amt:.2f}%)"
        local_cnt_str = f"{local_count:,}ê±´ ({local_ratio_cnt:.2f}%)"
        tourist_cnt_str = f"{tourist_count:,}ê±´ ({100 - local_ratio_cnt:.2f}%)"

        # ì¶œë ¥ í…Œì´ë¸”
        df = pd.DataFrame({
            "ìœ ì…ìœ í˜•": ["í˜„ì§€ì¸", "ì™¸ì§€ì¸", "í•©ê³„"],
            "ì†Œë¹„ê¸ˆì•¡": [local_amt_str, tourist_amt_str, f"{total_amount:,}ì²œì› (100%)"],
            "ì†Œë¹„ê±´ìˆ˜": [local_cnt_str, tourist_cnt_str, f"{total_count:,}ê±´ (100%)"],
            "ì†Œë¹„ë‹¨ê°€": [f"{local_unit:,}ì›", f"{tourist_unit:,}ì›", f"{total_unit:,}ì›"]
        })

        st.subheader("ğŸ“Š ì†Œë¹„í˜„í™© ìš”ì•½í‘œ")
        st.dataframe(df.set_index("ìœ ì…ìœ í˜•"))

        # âœ… GPT ì‹œì‚¬ì 
        with st.spinner("ğŸ¤– GPT ì‹œì‚¬ì  ìƒì„± ì¤‘..."):
            name = st.session_state.get("festival_name", "ë³¸ ì¶•ì œ")
            period = st.session_state.get("festival_period", "")
            location = st.session_state.get("festival_location", "")

            prompt = f"""ë‹¤ìŒì€ {name}({period}, {location})ì˜ ë°©ë¬¸ìœ í˜•ë³„ ì†Œë¹„í˜„í™© ë¶„ì„ì…ë‹ˆë‹¤.

â–¸ ë¬¸ì²´ëŠ” í–‰ì •ë³´ê³ ì„œ í˜•ì‹(ì˜ˆ: '~ë¡œ ë¶„ì„ë¨', '~ê¸°ì—¬í•˜ê³  ìˆìŒ', '~ë³´ì„')  
â–¸ ê° ë¬¸ì¥ì€ â–¸ ê¸°í˜¸ë¡œ ì‹œì‘í•˜ë©° 3~5ë¬¸ì¥ìœ¼ë¡œ ì‘ì„±  
â–¸ í˜„ì§€ì¸/ì™¸ì§€ì¸ì˜ ì†Œë¹„ê¸ˆì•¡, ì†Œë¹„ê±´ìˆ˜, ì†Œë¹„ë‹¨ê°€ ì°¨ì´ë¥¼ ë¶„ì„  
â–¸ ì™¸ì§€ì¸ì˜ ë‹¨ê°€ê°€ ë†’ë‹¤ë©´ ì²´ë¥˜ì†Œë¹„ ë° ê´€ê´‘íš¨ê³¼ ê°€ëŠ¥ì„± ì–¸ê¸‰  
â–¸ í•„ìš” ì‹œ â€» í‘œì‹œë¡œ ë¶€ê°€ ì„¤ëª… í¬í•¨  
â–¸ ë¶€ì •ì ì¸ í‘œí˜„ì€ í”¼í•˜ê³  ì¤‘ë¦½Â·ê¸ì •ì  íë¦„ ìœ ì§€

## ì…ë ¥ ì •ë³´:
- ì´ ì†Œë¹„ê¸ˆì•¡: {total_amount:,}ì²œì› / ì†Œë¹„ê±´ìˆ˜: {total_count:,}ê±´ / í‰ê·  ì†Œë¹„ë‹¨ê°€: {total_unit:,}ì›
- í˜„ì§€ì¸: {local_amount:,}ì²œì› / {local_count:,}ê±´ / {local_unit:,}ì›
- ì™¸ì§€ì¸: {tourist_amount:,}ì²œì› / {tourist_count:,}ê±´ / {tourist_unit:,}ì›

ìœ„ ì •ë³´ë¥¼ ë°”íƒ•ìœ¼ë¡œ ë°©ë¬¸ìœ í˜•ë³„ ì†Œë¹„ íŠ¹ì„±ì„ ì¤‘ì‹¬ìœ¼ë¡œ ì‹œì‚¬ì ì„ ì‘ì„±í•´ì£¼ì„¸ìš”.
"""

            response = client.chat.completions.create(
                model="gpt-4o",
                messages=[
                    {"role": "system", "content": "ë„ˆëŠ” ì§€ë°©ì •ë¶€ ì¶•ì œ ì†Œë¹„ë°ì´í„° ë¶„ì„ ì „ë¬¸ê°€ì•¼."},
                    {"role": "user", "content": prompt}
                ],
                temperature=0.5,
                max_tokens=600
            )

            st.subheader("ğŸ§  GPT ì‹œì‚¬ì ")
            st.write(response.choices[0].message.content)

