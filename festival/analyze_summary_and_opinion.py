#!/usr/bin/env python
# coding: utf-8

# In[ ]:


import streamlit as st
import pandas as pd
import os
from openai import OpenAI

client = OpenAI(api_key=st.secrets["OPENAI_API_KEY"])

# âœ… ì‹œì‚¬ì  ì˜ˆì‹œ ë¶ˆëŸ¬ì˜¤ê¸°
def load_insight_examples(section_id):
    try:
        path = f"press_release_app/data/insights/{section_id}.txt"
        with open(path, "r", encoding="utf-8") as f:
            return f.read()
    except FileNotFoundError:
        return ""

# âœ… 8. ë¶„ì„ê²°ê³¼ ìš”ì•½ ë° ì¢…í•©ì˜ê²¬
def analyze_summary_and_opinion():
    #st.subheader("ğŸ“Š 8. ë¶„ì„ê²°ê³¼ ìš”ì•½ ë° ì¢…í•©ì˜ê²¬")

    col1, col2 = st.columns(2)
    with col1:
        gpt_summary = st.button("ğŸ“ ë¶„ì„ê²°ê³¼(ìš”ì•½) ìƒì„± ë° ë³´ê¸°")
    with col2:
        gpt_opinion = st.button("ğŸ’¡ ì¢…í•©ì˜ê²¬(GPT ìƒì„±) ë³´ê¸°")

    analyze_summary_overview(gpt_generate=gpt_summary)
    analyze_final_opinion(gpt_generate=gpt_opinion)

# âœ… ë¶„ì„ê²°ê³¼ ìš”ì•½ ìƒì„±
def analyze_summary_overview(gpt_generate=False):
    name = st.session_state.get("festival_name", "ë³¸ ì¶•ì œ")
    period = st.session_state.get("festival_period", "")
    location = st.session_state.get("festival_location", "")
    summary_lines = []

    # âœ… 1. ë°©ë¬¸ê° ì´ê´„
    if all(key in st.session_state for key in ["summary_total_visitors", "summary_local_visitors", "summary_tourist_visitors"]):
        total = st.session_state["summary_total_visitors"]
        local = st.session_state["summary_local_visitors"]
        tourist = st.session_state["summary_tourist_visitors"]
        summary_lines.append(f"â ì´ ê´€ê´‘ê° ìˆ˜ëŠ” {total:,}ëª…ì´ë©°, ì´ ì¤‘ í˜„ì§€ì¸ì€ {local:,}ëª…({local/total:.1%}), ì™¸ì§€ì¸ì€ {tourist:,}ëª…({tourist/total:.1%})ì„")

    # âœ… 2. ì‹œê°„ëŒ€ë³„ ë¶„í¬
    if "summary_time_distribution_df" in st.session_state:
        df = st.session_state["summary_time_distribution_df"]
        summary_lines.append("â ì‹œê°„ëŒ€ë³„ ë¶„í¬ëŠ” 21~24ì‹œ êµ¬ê°„ì— ê°€ì¥ ì§‘ì¤‘ë˜ì–´ ìˆìŒ")

    # âœ… 3. ì „Â·ì¤‘Â·í›„ ë¶„ì„
    if "summary_before_after_df" in st.session_state:
        df = st.session_state["summary_before_after_df"]
        try:
            before = df.iloc[2, 1]  # í•©ê³„, ì¶•ì œ ì „
            during = df.iloc[2, 2]  # í•©ê³„, ì¶•ì œ ê¸°ê°„
            summary_lines.append(f"â ì¶•ì œê¸°ê°„ ì´ ë°©ë¬¸ê° ìˆ˜ëŠ” {during}ëª…ìœ¼ë¡œ, ì¶•ì œ ì „(5ì¼) ëŒ€ë¹„ ëšœë ·í•œ ì¦ê°€ ì¶”ì„¸")
        except:
            pass

    # âœ… 4. ì—°ë ¹ëŒ€ë³„ ìš”ì•½
    if "summary_age_group_df" in st.session_state:
        summary_lines.append("â ì—°ë ¹ëŒ€ë³„ë¡œëŠ” 20ëŒ€ì˜ ì°¸ì—¬ìœ¨ì´ ê°€ì¥ ë†’ì•„ ì Šì€ ì¸µ ì¤‘ì‹¬ì˜ ì¶•ì œë¡œ í‰ê°€ë¨")

    # âœ… 5. ì™¸ì§€ì¸ ì²´ë¥˜ ë¶„ì„
    if "summary_visitor_after_24h_grouped" in st.session_state:
        df = st.session_state["summary_visitor_after_24h_grouped"]
        chungju_row = df[df["full_region"].str.contains("ì¶©ì£¼ì‹œ")]
        if not chungju_row.empty:
            stay_count = int(chungju_row.iloc[0]["ê´€ê´‘ê°ìˆ˜"])
            stay_rate = float(chungju_row.iloc[0]["ë¹„ìœ¨"])
            summary_lines.append(f"â ì™¸ì§€ì¸ ì¤‘ {stay_rate:.2f}%({stay_count:,}ëª…)ëŠ” ì¶©ì£¼ì— 24ì‹œê°„ ì´ìƒ ì²´ë¥˜í•˜ë©° ê´€ê´‘ í™œë™ì„ ì´ì–´ê°„ ê²ƒìœ¼ë¡œ ë¶„ì„ë¨")

    # âœ… ìš”ì•½ ì¶œë ¥
    st.markdown("### ğŸ§¾ ë¶„ì„ê²°ê³¼ ìš”ì•½")
    st.text("\n".join(summary_lines))

    # âœ… GPT ìš”ì•½ ìƒì„±
    if gpt_generate:
        reference = load_insight_examples("summary_overview")
        prompt = f"""
ğŸ“Œ ë³¸ ë¶„ì„ì€ KT ê´€ê´‘ì¸êµ¬ / êµ­ë¯¼ì¹´ë“œ ë§¤ì¶œ ë°ì´í„°ë¥¼ ê¸°ì´ˆë¡œ ì‹œì¥ì ìœ ìœ¨ì— ë”°ë¥¸ ë³´ì •ê³„ìˆ˜ë¥¼ ì ìš©Â·ì‚°ì¶œí•œ {name}({period}, {location}) ì¶•ì œì˜ ë°©ë¬¸ê°ê³¼ ë§¤ì¶œí˜„í™©ì„ ë¶„ì„í•œ ê²°ê³¼ì„

[ìš”ì•½ ë°ì´í„°]\n{chr(10).join(summary_lines)}

â–¸ ê° ë¬¸ì¥ì€ â ê¸°í˜¸ë¡œ ì‹œì‘í•˜ê³ , ë¬¸ì¥ì´ ë‹¨ì ˆë˜ì§€ ì•Šë„ë¡ ìì—°ìŠ¤ëŸ½ê²Œ ì—°ê²°í•  ê²ƒ  
â–¸ ì´ ê´€ê´‘ê° ìˆ˜, ì¦ê°€ìœ¨, ì‹œê°„ëŒ€, ì—°ë ¹ëŒ€, ì™¸ì§€ì¸ ì²´ë¥˜, ì†Œë¹„ íë¦„ ë“±ì„ ì¢…í•© ë°˜ì˜í•˜ì—¬ 6ë¬¸ì¥ ì´ë‚´ë¡œ êµ¬ì„±í•  ê²ƒ  
â–¸ í–‰ì • ë³´ê³ ì„œ ìŠ¤íƒ€ì¼ë¡œ ì‘ì„±í•  ê²ƒ  
[ìœ ì‚¬ ì‹œì‚¬ì  ì˜ˆì‹œ]\n{reference}
"""

        with st.spinner("GPTê°€ ë¶„ì„ê²°ê³¼ ìš”ì•½ ì¤‘..."):
            response = client.chat.completions.create(
                model="gpt-4o",
                messages=[
                    {"role": "system", "content": "ë„ˆëŠ” ì§€ë°©ì •ë¶€ ì¶•ì œ ë°ì´í„°ë¥¼ ë¶„ì„í•˜ëŠ” ì „ë¬¸ê°€ì•¼."},
                    {"role": "user", "content": prompt}
                ],
                temperature=0.5,
                max_tokens=1000
            )
            st.subheader("ğŸ§¾ GPT ë¶„ì„ê²°ê³¼ ìš”ì•½")
            st.write(response.choices[0].message.content)

        # âœ… ì¢…í•©ì˜ê²¬ìš©ìœ¼ë¡œ ì €ì¥
        st.session_state["final_summary_text"] = "\n".join(summary_lines)

# âœ… ì¢…í•©ì˜ê²¬
def analyze_final_opinion(gpt_generate=False):
    name = st.session_state.get("festival_name", "ë³¸ ì¶•ì œ")
    period = st.session_state.get("festival_period", "")
    location = st.session_state.get("festival_location", "")

    # âœ… summaryê°€ ì—†ìœ¼ë©´ ê²½ê³ 
    if gpt_generate and "final_summary_text" not in st.session_state:
        st.warning("âš ï¸ ë¨¼ì € 'ë¶„ì„ê²°ê³¼ ìš”ì•½ ìƒì„±' ë²„íŠ¼ì„ ëˆŒëŸ¬ì£¼ì„¸ìš”.")
        return

    if gpt_generate:
        summary_lines = st.session_state["final_summary_text"]
        reference = load_insight_examples("final_opinion")

        prompt = f"""ë‹¤ìŒì€ {name}({period}, {location}) ì¶•ì œì˜ ë¶„ì„ ìš”ì•½ì…ë‹ˆë‹¤.

{summary_lines}

[ì°¸ê³ ìë£Œ]
{reference}

ìœ„ ë‚´ìš©ì„ ë°”íƒ•ìœ¼ë¡œ ì •ì±…ì  ì‹œì‚¬ì  ì¤‘ì‹¬ì˜ ì¢…í•© ì˜ê²¬ì„ 5~7ë¬¸ì¥ìœ¼ë¡œ ì‘ì„±í•´ì£¼ì„¸ìš”.
â ë°©ë¬¸ê° íŠ¹ì„±ê³¼ ë™í–¥ ë¶„ì„  
â ì§€ì—­ ê²½ì œ/ì†Œë¹„/ì²´ë¥˜ ê¸°ì—¬ë„ í•´ì„  
â ê´€ê´‘ ì „ëµ/ìš´ì˜ í”„ë¡œê·¸ë¨ ê°œì„  ë°©í–¥ ì œì‹œ í¬í•¨
"""

        with st.spinner("GPTê°€ ì¢…í•©ì˜ê²¬ì„ ì‘ì„± ì¤‘ì…ë‹ˆë‹¤..."):
            response = client.chat.completions.create(
                model="gpt-4o",
                messages=[
                    {"role": "system", "content": "ë„ˆëŠ” ì¶©ì£¼ì‹œ ì¶•ì œ ë°ì´í„°ë¥¼ ë¶„ì„í•˜ê³  ì •ì±… ì œì•ˆê¹Œì§€ ë„ì¶œí•˜ëŠ” ì§€ë°©í–‰ì • ì „ë¬¸ê°€ì•¼."},
                    {"role": "user", "content": prompt}
                ],
                temperature=0.5,
                max_tokens=1000
            )
            st.subheader("ğŸ’¡ GPT ì¢…í•©ì˜ê²¬")
            st.write(response.choices[0].message.content)

