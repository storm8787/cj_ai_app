#!/usr/bin/env python
# coding: utf-8

# In[ ]:


import streamlit as st
import pandas as pd
import os
from openai import OpenAI

client = OpenAI(api_key=st.secrets["OPENAI_API_KEY"])

# âœ… ì‹œì‚¬ì  ì˜ˆì‹œ ë¶ˆëŸ¬ì˜¤ê¸°
def load_insight_examples(section_id):
    try:
        path = f"press_release_app/data/insights/{section_id}.txt"
        with open(path, "r", encoding="utf-8") as f:
            return f.read()
    except FileNotFoundError:
        return ""

# âœ… 8. ë¶„ì„ê²°ê³¼ ìš”ì•½ ë° ì¢…í•©ì˜ê²¬
def analyze_summary_and_opinion():
    st.subheader("ğŸ“Š 8. ë¶„ì„ê²°ê³¼ ìš”ì•½ ë° ì¢…í•©ì˜ê²¬")

    col1, col2 = st.columns(2)
    with col1:
        gpt_summary = st.button("ğŸ“ ë¶„ì„ê²°ê³¼(ìš”ì•½) ìƒì„± ë° ë³´ê¸°")
    with col2:
        gpt_opinion = st.button("ğŸ’¡ ì¢…í•©ì˜ê²¬(GPT ìƒì„±) ë³´ê¸°")

    analyze_summary_overview(gpt_generate=gpt_summary)
    analyze_final_opinion(gpt_generate=gpt_opinion)

# âœ… ë¶„ì„ê²°ê³¼ ìš”ì•½
def analyze_summary_overview(gpt_generate=False):
    name = st.session_state.get("festival_name", "ë³¸ ì¶•ì œ")
    period = st.session_state.get("festival_period", "")
    location = st.session_state.get("festival_location", "")
    summary_lines = []

    if "summary_total_text" in st.session_state:
        summary_lines.append("ğŸ“Œ [1. ë°©ë¬¸ê° ì´ê´„]")
        summary_lines.append(st.session_state["summary_total_text"])

    if "summary_daily_table" in st.session_state:
        summary_lines.append("\nğŸ“Œ [2. ì¼ìë³„ ë°©ë¬¸ê°]")
        df = st.session_state["summary_daily_table"]
        for _, row in df.iterrows():
            summary_lines.append(f"- {row['ë‚ ì§œ']}: í˜„ì§€ì¸ {row['í˜„ì§€ì¸ ë°©ë¬¸ê°']:,} / ì™¸ì§€ì¸ {row['ì™¸ì§€ì¸ ë°©ë¬¸ê°']:,} / ì „ì²´ {row['ì „ì²´ ë°©ë¬¸ê°']:,}")

    if "summary_time_distribution" in st.session_state:
        summary_lines.append("\nğŸ“Œ [3. ì‹œê°„ëŒ€ë³„ ê´€ê´‘ê° ë¶„í¬]")
        summary_lines.append(st.session_state["summary_time_distribution"])

    if "summary_before_after" in st.session_state:
        summary_lines.append("\nğŸ“Œ [4. ì¶•ì œ ì „Â·ì¤‘Â·í›„ ë°©ë¬¸ê°]")
        summary_lines.append(st.session_state["summary_before_after"])

    if "summary_age_group_text" in st.session_state:
        summary_lines.append("\nğŸ“Œ [5. ì—°ë ¹ëŒ€ë³„ ë°©ë¬¸ê°]")
        summary_lines.append(st.session_state["summary_age_group_text"])

    # âœ… (ìš”ì•½ìš©) ì‹œë„ë³„ ì™¸ì§€ì¸ ë°©ë¬¸ê° â€“ ìƒìœ„ 5ê°œë§Œ
    if "summary_visitor_by_province_sido" in st.session_state:
        summary_lines.append("\nğŸ“Œ [7-1. ì‹œë„ë³„ ì™¸ì§€ì¸ ë°©ë¬¸ê° ìƒìœ„ 5]")
        df = st.session_state["summary_visitor_by_province_sido"]
        df = df[df["ì‹œë„_2"].notnull() & (df["ì‹œë„_2"] != "í•©ê³„")].head(5)
        for _, row in df.iterrows():
            summary_lines.append(f"- {row['ì‹œë„_2']}: {row['ê´€ê´‘ê°ìˆ˜_2']}ëª… ({row['ë¹„ìœ¨_2']})")

    # âœ… (ìš”ì•½ìš©) ì‹œêµ°êµ¬ë³„ ì™¸ì§€ì¸ ë°©ë¬¸ê° â€“ ìƒìœ„ 5ê°œë§Œ
    if "summary_visitor_by_province_gungu" in st.session_state:
        summary_lines.append("\nğŸ“Œ [7-2. ì‹œêµ°êµ¬ë³„ ì™¸ì§€ì¸ ë°©ë¬¸ê° ìƒìœ„ 5]")
        df = st.session_state["summary_visitor_by_province_gungu"]
        df = df[df["full_region_2"].notnull() & (df["full_region_2"] != "í•©ê³„")].head(5)
        for _, row in df.iterrows():
            summary_lines.append(f"- {row['full_region_2']}: {row['ê´€ê´‘ê°ìˆ˜_2']}ëª… ({row['ë¹„ìœ¨_2']})")

    # âœ… (ìš”ì•½ìš©) 24ì‹œê°„ ì´í›„ ì§€ì—­ â€“ ìƒìœ„ 5ê°œë§Œ
    if "summary_visitor_after_24h_grouped" in st.session_state:
        summary_lines.append("\nğŸ“Œ [7-3. ì™¸ì§€ì¸ 24ì‹œê°„ ì´í›„ ì§€ì—­ ìƒìœ„ 5]")
        df = st.session_state["summary_visitor_after_24h_grouped"]
        df = df.sort_values(by="ê´€ê´‘ê°ìˆ˜", ascending=False).head(5)
        for _, row in df.iterrows():
            summary_lines.append(f"- {row['full_region']}: {row['ê´€ê´‘ê°ìˆ˜']:,}ëª… ({row['ë¹„ìœ¨']:.2f}%)")

    # âœ… ìš”ì•½ ì¶œë ¥
    st.markdown("### ğŸ§¾ ë¶„ì„ê²°ê³¼ ìš”ì•½")
    st.text("\n".join(summary_lines))

    # âœ… GPT ìš”ì•½ ìƒì„±
    if gpt_generate:
        reference = load_insight_examples("summary_overview")

        prompt = f"""ğŸ“Œ ë³¸ ë¶„ì„ì€ KT ê´€ê´‘ì¸êµ¬ / êµ­ë¯¼ì¹´ë“œ ë§¤ì¶œ ë°ì´í„°ë¥¼ ê¸°ì´ˆë¡œ ì‹œì¥ì ìœ ìœ¨ì— ë”°ë¥¸ ë³´ì •ê³„ìˆ˜ë¥¼ ì ìš©Â·ì‚°ì¶œí•œ {name}({period}, {location}) ì¶•ì œì˜ ë°©ë¬¸ê°ê³¼ ë§¤ì¶œí˜„í™©ì„ ë¶„ì„í•œ ê²°ê³¼ì„

ë¶„ì„ ê°œìš”:
{chr(10).join(summary_lines)}

[ì°¸ê³ ìë£Œ]
{reference}

ì•„ë˜ í˜•ì‹ì— ë§ì¶° 5~7ë¬¸ì¥ìœ¼ë¡œ í–‰ì • ë³´ê³ ì„œ ìŠ¤íƒ€ì¼ì˜ ë¶„ì„ê²°ê³¼ë¥¼ ì‘ì„±í•˜ì„¸ìš”.

â ì´ ê´€ê´‘ê° ìˆ˜, ì „ë…„ ëŒ€ë¹„ ì¦ê°  
  - í˜„ì§€ì¸ê³¼ ì™¸ì§€ì¸ ê°ê° ìˆ˜ì¹˜ ë° ì¦ê° í¬í•¨  
â ì¼í‰ê·  ê´€ê´‘ê° ì¦ê° / ì¼ë°˜ ì‹œê¸° ëŒ€ë¹„ ë³€í™”ìœ¨ í¬í•¨  
â ì—°ë ¹ëŒ€, ìš”ì¼, ì‹œê°„ëŒ€ë³„ íŠ¹ì§•  
â ì²´ë¥˜í˜• ê´€ê´‘ê°ì˜ ë¹„ìœ¨ ë° ì—°ê³„ê´€ê´‘ ì‹œì‚¬ì   
â ì „ë°˜ì  í‰ê°€: ë°©ë¬¸ê° íë¦„, í”„ë¡œê·¸ë¨ íŠ¹ì„±, ê¸°í›„ ë“± ì¢…í•©ì  í•´ì„

ì´ í˜•ì‹ì„ ì—„ê²©íˆ ë”°ë¥´ì„¸ìš”.
"""

        with st.spinner("GPTê°€ ë¶„ì„ê²°ê³¼ ìš”ì•½ ì¤‘..."):
            response = client.chat.completions.create(
                model="gpt-4o",
                messages=[
                    {"role": "system", "content": "ë„ˆëŠ” ì§€ë°©ì •ë¶€ ì¶•ì œ ë°ì´í„°ë¥¼ ë¶„ì„í•˜ëŠ” ì „ë¬¸ê°€ì•¼."},
                    {"role": "user", "content": prompt}
                ],
                temperature=0.5,
                max_tokens=900
            )
            st.subheader("ğŸ§¾ GPT ë¶„ì„ê²°ê³¼ ìš”ì•½")
            st.write(response.choices[0].message.content)

        # âœ… ì¢…í•©ì˜ê²¬ìš©ìœ¼ë¡œ ì €ì¥
        st.session_state["final_summary_text"] = "\n".join(summary_lines)

# âœ… ì¢…í•©ì˜ê²¬
def analyze_final_opinion(gpt_generate=False):
    name = st.session_state.get("festival_name", "ë³¸ ì¶•ì œ")
    period = st.session_state.get("festival_period", "")
    location = st.session_state.get("festival_location", "")

    # âœ… summaryê°€ ì—†ìœ¼ë©´ ê²½ê³ 
    if gpt_generate and "final_summary_text" not in st.session_state:
        st.warning("âš ï¸ ë¨¼ì € 'ë¶„ì„ê²°ê³¼ ìš”ì•½ ìƒì„±' ë²„íŠ¼ì„ ëˆŒëŸ¬ì£¼ì„¸ìš”.")
        return

    if gpt_generate:
        summary_lines = st.session_state["final_summary_text"]
        reference = load_insight_examples("final_opinion")

        prompt = f"""ë‹¤ìŒì€ {name}({period}, {location}) ì¶•ì œì˜ ë¶„ì„ ìš”ì•½ì…ë‹ˆë‹¤.

{summary_lines}

[ì°¸ê³ ìë£Œ]
{reference}

ìœ„ ë‚´ìš©ì„ ë°”íƒ•ìœ¼ë¡œ ì •ì±…ì  ì‹œì‚¬ì  ì¤‘ì‹¬ì˜ ì¢…í•© ì˜ê²¬ì„ 5~7ë¬¸ì¥ìœ¼ë¡œ ì‘ì„±í•´ì£¼ì„¸ìš”.
â ë°©ë¬¸ê° íŠ¹ì„±ê³¼ ë™í–¥ ë¶„ì„  
â ì§€ì—­ ê²½ì œ/ì†Œë¹„/ì²´ë¥˜ ê¸°ì—¬ë„ í•´ì„  
â ê´€ê´‘ ì „ëµ/ìš´ì˜ í”„ë¡œê·¸ë¨ ê°œì„  ë°©í–¥ ì œì‹œ í¬í•¨
"""

        with st.spinner("GPTê°€ ì¢…í•©ì˜ê²¬ì„ ì‘ì„± ì¤‘ì…ë‹ˆë‹¤..."):
            response = client.chat.completions.create(
                model="gpt-4o",
                messages=[
                    {"role": "system", "content": "ë„ˆëŠ” ì¶©ì£¼ì‹œ ì¶•ì œ ë°ì´í„°ë¥¼ ë¶„ì„í•˜ê³  ì •ì±… ì œì•ˆê¹Œì§€ ë„ì¶œí•˜ëŠ” ì§€ë°©í–‰ì • ì „ë¬¸ê°€ì•¼."},
                    {"role": "user", "content": prompt}
                ],
                temperature=0.5,
                max_tokens=1000
            )
            st.subheader("ğŸ’¡ GPT ì¢…í•©ì˜ê²¬")
            st.write(response.choices[0].message.content)

