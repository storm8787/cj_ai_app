#!/usr/bin/env python
# coding: utf-8

# In[ ]:


import streamlit as st
import pandas as pd
import os
from openai import OpenAI

client = OpenAI(api_key=st.secrets["OPENAI_API_KEY"])

def load_insight_examples(section_id):
    try:
        path = f"press_release_app/data/insights/{section_id}.txt"
        with open(path, "r", encoding="utf-8") as f:
            return f.read()
    except FileNotFoundError:
        return ""

from festival.analyze_summary_overview import analyze_summary_overview
from festival.analyze_final_opinion import analyze_final_opinion

def analyze_summary_and_opinion():
    st.subheader("ğŸ“Š 8. ë¶„ì„ê²°ê³¼ ìš”ì•½ ë° ì¢…í•©ì˜ê²¬")

    col1, col2 = st.columns(2)

    with col1:
        if st.button("ğŸ“ ë¶„ì„ê²°ê³¼(ìš”ì•½) ë³´ê¸°"):
            analyze_summary_overview()

    with col2:
        if st.button("ğŸ’¡ ì¢…í•©ì˜ê²¬(GPT ìƒì„±) ë³´ê¸°"):
            analyze_final_opinion()

def analyze_summary_overview():
    st.subheader("ğŸ§¾ 8-1. ë¶„ì„ê²°ê³¼ ìš”ì•½")

    name = st.session_state.get("festival_name", "ë³¸ ì¶•ì œ")
    period = st.session_state.get("festival_period", "")
    location = st.session_state.get("festival_location", "")
    summary_lines = []

    # ì„¸ì…˜ì—ì„œ ìš”ì•½ ë‚´ìš© ê°€ì ¸ì˜¤ê¸° (1~7ë²ˆ ë¶„ì„ê¸° ë°ì´í„° ê¸°ë°˜)
    if "summary_total_text" in st.session_state:
        summary_lines.append("ğŸ“Œ [1. ë°©ë¬¸ê° ì´ê´„]")
        summary_lines.append(st.session_state["summary_total_text"])
    if "summary_daily_table" in st.session_state:
        summary_lines.append("\nğŸ“Œ [2. ì¼ìë³„ ë°©ë¬¸ê°]")
        for _, row in st.session_state["summary_daily_table"].iterrows():
            summary_lines.append(f"- {row['ë‚ ì§œ']}: í˜„ì§€ì¸ {row['í˜„ì§€ì¸ ë°©ë¬¸ê°']:,} / ì™¸ì§€ì¸ {row['ì™¸ì§€ì¸ ë°©ë¬¸ê°']:,} / ì „ì²´ {row['ì „ì²´ ë°©ë¬¸ê°']:,}")
    if "summary_time_distribution" in st.session_state:
        summary_lines.append("\nğŸ“Œ [3. ì‹œê°„ëŒ€ë³„ ê´€ê´‘ê° ë¶„í¬]")
        summary_lines.append(st.session_state["summary_time_distribution"])
    if "summary_before_after" in st.session_state:
        summary_lines.append("\nğŸ“Œ [4. ì¶•ì œ ì „Â·ì¤‘Â·í›„ ë°©ë¬¸ê°]")
        summary_lines.append(st.session_state["summary_before_after"])
    if "summary_age_group_text" in st.session_state:
        summary_lines.append("\nğŸ“Œ [5. ì—°ë ¹ëŒ€ë³„ ë°©ë¬¸ê°]")
        summary_lines.append(st.session_state["summary_age_group_text"])
    if "summary_gender_by_age_df" in st.session_state:
        summary_lines.append("\nğŸ“Œ [6. ì—°ë ¹ë³„ ì„±ë³„ ë°©ë¬¸ê°]")
        df = st.session_state["summary_gender_by_age_df"]
        for _, row in df.iterrows():
            summary_lines.append(f"- {row['ì—°ë ¹êµ¬ë¶„']}: ë‚¨ì {row['ë‚¨ì']}ëª… ({row['ë‚¨ìë¹„ìœ¨']}%), ì—¬ì {row['ì—¬ì']}ëª… ({row['ì—¬ìë¹„ìœ¨']}%)")
    if "summary_visitor_by_province_sido" in st.session_state:
        summary_lines.append("\nğŸ“Œ [7-1. ì‹œë„ë³„ ì™¸ì§€ì¸ ë°©ë¬¸ê°]")
        df = st.session_state["summary_visitor_by_province_sido"]
        for _, row in df.iterrows():
            if row["ì‹œë„_2"] not in ["", "í•©ê³„", None]:
                summary_lines.append(f"- {row['ì‹œë„_2']}: {row['ê´€ê´‘ê°ìˆ˜_2']}ëª… ({row['ë¹„ìœ¨_2']})")
    if "summary_visitor_by_province_gungu" in st.session_state:
        summary_lines.append("\nğŸ“Œ [7-2. ì‹œêµ°êµ¬ë³„ ì™¸ì§€ì¸ ë°©ë¬¸ê°]")
        df = st.session_state["summary_visitor_by_province_gungu"]
        for _, row in df.iterrows():
            if row["full_region_2"] not in ["", "í•©ê³„", "ê¸°íƒ€", None]:
                summary_lines.append(f"- {row['full_region_2']}: {row['ê´€ê´‘ê°ìˆ˜_2']}ëª… ({row['ë¹„ìœ¨_2']})")
    if "summary_visitor_after_24h_grouped" in st.session_state:
        summary_lines.append("\nğŸ“Œ [7-3. ì™¸ì§€ì¸ 24ì‹œê°„ ì´í›„ ì§€ì—­]")
        df = st.session_state["summary_visitor_after_24h_grouped"]
        for _, row in df.iterrows():
            summary_lines.append(f"- {row['full_region']}: {row['ê´€ê´‘ê°ìˆ˜']:,}ëª… ({row['ë¹„ìœ¨']:.2f}%)")

    # GPT ìš”ì•½ ìƒì„±
    if st.button("ğŸ§  ë¶„ì„ê²°ê³¼ ìš”ì•½ ìƒì„±"):
        reference = load_insight_examples("summary_overview")
        prompt = f"""ë‹¤ìŒì€ {name}({period}, {location}) ì¶•ì œì˜ ë°ì´í„° ê¸°ë°˜ ë¶„ì„ê²°ê³¼ì…ë‹ˆë‹¤.

{chr(10).join(summary_lines)}

[ì°¸ê³ ìë£Œ]
{reference}

ìœ„ ë‚´ìš©ì„ ë°”íƒ•ìœ¼ë¡œ ë°©ë¬¸ê° ìˆ˜, ì„±ê²©, ì²´ë¥˜, ì†Œë¹„ ë“± ì£¼ìš” ì§€í‘œ ì¤‘ì‹¬ìœ¼ë¡œ ë¶„ì„ê²°ê³¼ë¥¼ ê³µê³µë³´ê³ ì„œ ìŠ¤íƒ€ì¼ë¡œ 5~7ë¬¸ì¥ìœ¼ë¡œ ì‘ì„±í•´ì£¼ì„¸ìš”.
"""
        with st.spinner("GPTê°€ ë¶„ì„ê²°ê³¼ ìš”ì•½ ì¤‘..."):
            response = client.chat.completions.create(
                model="gpt-4o",
                messages=[
                    {"role": "system", "content": "ë„ˆëŠ” ì¶•ì œ ë°ì´í„°ë¥¼ ì •ë¦¬í•˜ëŠ” ì§€ë°©í–‰ì • ì „ë¬¸ê°€ì•¼."},
                    {"role": "user", "content": prompt}
                ],
                temperature=0.5,
                max_tokens=900
            )
            st.subheader("ğŸ§¾ GPT ë¶„ì„ê²°ê³¼ ìš”ì•½")
            st.write(response.choices[0].message.content)

def analyze_final_opinion():
    st.subheader("ğŸ’¬ 8-2. ì¢…í•©ì˜ê²¬ (ì •ì±…ì  ì‹œì‚¬ì )")

    name = st.session_state.get("festival_name", "ë³¸ ì¶•ì œ")
    period = st.session_state.get("festival_period", "")
    location = st.session_state.get("festival_location", "")
    
    # GPT ì¢…í•©ì˜ê²¬ ìƒì„±
    if st.button("ğŸ§  ì¢…í•©ì˜ê²¬ ìƒì„±"):
        summary_lines = st.session_state.get("final_summary_text", "")
        reference = load_insight_examples("final_opinion")

        prompt = f"""ë‹¤ìŒì€ {name}({period}, {location}) ì¶•ì œì˜ ìš”ì•½ ë¶„ì„ ê²°ê³¼ì…ë‹ˆë‹¤.

{summary_lines}

[ì°¸ê³ ìë£Œ]
{reference}

ìœ„ ë‚´ìš©ì„ ë°”íƒ•ìœ¼ë¡œ ì •ì±…ì  ì‹œì‚¬ì  ì¤‘ì‹¬ì˜ ì¢…í•©ì ì¸ ì˜ê²¬ì„ 5~7ë¬¸ì¥ìœ¼ë¡œ ì‘ì„±í•´ì£¼ì„¸ìš”.
"""
        with st.spinner("GPTê°€ ì¢…í•©ì˜ê²¬ì„ ì‘ì„± ì¤‘ì…ë‹ˆë‹¤..."):
            response = client.chat.completions.create(
                model="gpt-4o",
                messages=[
                    {"role": "system", "content": "ë„ˆëŠ” ì¶©ì£¼ì‹œ ì¶•ì œ ë°ì´í„°ë¥¼ ë¶„ì„í•˜ê³  ì •ì±… ì œì•ˆê¹Œì§€ ë„ì¶œí•˜ëŠ” ì§€ë°©í–‰ì • ì „ë¬¸ê°€ì•¼."},
                    {"role": "user", "content": prompt}
                ],
                temperature=0.5,
                max_tokens=1000
            )
            st.subheader("ğŸ’¡ GPT ì¢…í•©ì˜ê²¬")
            st.write(response.choices[0].message.content)

