#!/usr/bin/env python
# coding: utf-8

# In[ ]:


import streamlit as st
import pandas as pd
import io
from openai import OpenAI
import os

client = OpenAI(api_key=st.secrets["OPENAI_API_KEY"])

# âœ… ì‹œì‚¬ì  ì˜ˆì‹œ ë¶ˆëŸ¬ì˜¤ê¸°
def load_insight_examples(section_id):
    try:
        path = os.path.join("press_release_app", "data", "insights", f"{section_id}.txt")
        with open(path, "r", encoding="utf-8") as f:
            return f.read()
    except FileNotFoundError:
        return ""

def analyze_visitor_by_province():
    st.subheader("ğŸ“Š 7-1. ì‹œë„ ë° ì‹œêµ°êµ¬ë³„ ì™¸ì§€ì¸ ë°©ë¬¸ê° ê±°ì£¼ì§€ ë¶„ì„ê¸°")

    # âœ… í…œí”Œë¦¿ ë‹¤ìš´ë¡œë“œ ì œê³µ
    template_df = pd.DataFrame(columns=["ì‹œë„", "ì‹œêµ°êµ¬", "ê´€ê´‘ê°ìˆ˜(%)"])
    buffer = io.BytesIO()
    template_df.to_excel(buffer, index=False)
    buffer.seek(0)
    st.download_button(
        label="ğŸ“¥ 7-1 í…œí”Œë¦¿ ë‹¤ìš´ë¡œë“œ",
        data=buffer,
        file_name="7-1. template.xlsx",
        mime="application/vnd.openxmlformats-officedocument.spreadsheetml.sheet"
    )

    # âœ… ê¸°ì¤€ ë°©ë¬¸ê° ìˆ˜ ì…ë ¥
    total_visitors = st.number_input("ğŸ”¢ ê¸°ì¤€ ì™¸ì§€ì¸ ë°©ë¬¸ê° ìˆ˜ë¥¼ ì…ë ¥í•˜ì„¸ìš”", min_value=1, step=1)

    # âœ… íŒŒì¼ ì—…ë¡œë“œ
    uploaded_file = st.file_uploader("ğŸ“‚ ì‹œë„ë³„ ë¹„ìœ¨ ë°ì´í„° ì—‘ì…€ ì—…ë¡œë“œ", type=["xlsx"])
    if not uploaded_file or total_visitors <= 0:
        return

    # âœ… ë°ì´í„° ë¡œë“œ ë° ìœ íš¨ì„± í™•ì¸
    df = pd.read_excel(uploaded_file).dropna(how="all")
    df.columns = [col.strip() for col in df.columns]

    expected_cols = ["ì‹œë„", "ì‹œêµ°êµ¬", "ê´€ê´‘ê°ìˆ˜(%)"]
    if not all(col in df.columns for col in expected_cols):
        st.error("âŒ 'ì‹œë„', 'ì‹œêµ°êµ¬', 'ê´€ê´‘ê°ìˆ˜(%)' ì»¬ëŸ¼ì´ í¬í•¨ëœ íŒŒì¼ì„ ì—…ë¡œë“œí•´ì£¼ì„¸ìš”.")
        return

    # âœ… ë¹„ìœ¨ ë³€í™˜ ë° ê´€ê´‘ê° ìˆ˜ ê³„ì‚°
    df["ë¹„ìœ¨"] = df["ê´€ê´‘ê°ìˆ˜(%)"].astype(str).str.replace("%", "").astype(float) / 100
    df["ê´€ê´‘ê°ìˆ˜"] = (df["ë¹„ìœ¨"] * total_visitors).round().astype(int)

    # âœ… ì‹œë„ ê¸°ì¤€ ê·¸ë£¹í™”
    grouped = df.groupby("ì‹œë„", as_index=False)["ê´€ê´‘ê°ìˆ˜"].sum()
    grouped["ë¹„ìœ¨"] = (grouped["ê´€ê´‘ê°ìˆ˜"] / total_visitors * 100).round(2).astype(str) + "%"

    # âœ… ì •ë ¬ í›„ 2ì—´ ë¶„í• 
    grouped = grouped.sort_values(by="ê´€ê´‘ê°ìˆ˜", ascending=False).reset_index(drop=True)
    midpoint = len(grouped) // 2 + len(grouped) % 2
    left = grouped.iloc[:midpoint].reset_index(drop=True)
    right = grouped.iloc[midpoint:].reset_index(drop=True)

    # âœ… ì ‘ë¯¸ì–´ ë¶™ì´ê¸° (ì»¬ëŸ¼ëª… ì¤‘ë³µ ë°©ì§€)
    left.columns = [f"{col}_1" for col in left.columns]
    right.columns = [f"{col}_2" for col in right.columns]
    
    result_df = pd.concat([left, right], axis=1)

    # âœ… ê²°ê³¼ DataFrame êµ¬ì¡° ë³µì œ
    empty_row = pd.DataFrame(columns=result_df.columns)

    # âœ… ë”•ì…”ë„ˆë¦¬ í˜•íƒœë¡œ ê°’ ì±„ìš°ê¸°
    last_row_values = {}
    for col in result_df.columns:
        if "ì‹œë„" in col:
            last_row_values[col] = "í•©ê³„"
        elif "ê´€ê´‘ê°ìˆ˜" in col:
            last_row_values[col] = grouped["ê´€ê´‘ê°ìˆ˜"].sum()
        elif "ë¹„ìœ¨" in col:
            last_row_values[col] = "100.00%"
        else:
            last_row_values[col] = ""

    # âœ… DataFrameìœ¼ë¡œ ë³€í™˜, result_dfì™€ ë™ì¼í•œ êµ¬ì¡°ë¡œ ë³´ì¥
    total_row_df = pd.DataFrame([last_row_values], columns=result_df.columns)

    # âœ… ì•ˆì „í•˜ê²Œ ë¶™ì´ê¸°
    result_df = pd.concat([result_df, total_row_df], ignore_index=True)

    # âœ… ì¶œë ¥
    st.markdown("#### ğŸ“‹ ì‹œë„ë³„ ë¶„ì„ ê²°ê³¼")
    st.dataframe(result_df, use_container_width=True)

# -------------------------
# âœ… 7-2. ì‹œêµ°êµ¬ë³„ ë°©ë¬¸ê° ë¶„ì„
# -------------------------

    st.markdown("### ğŸ™ï¸ 7-2. ì‹œêµ°êµ¬ë³„ ì™¸ì§€ì¸ ë°©ë¬¸ê° í˜„í™©")

    # âœ… êµ¬ ë‹¨ìœ„ë¥¼ ì‹œë¡œ ë³‘í•©í•  ì‹œ ë¦¬ìŠ¤íŠ¸
    merge_target_cities = [
        "ì²­ì£¼ì‹œ", "ìˆ˜ì›ì‹œ", "ì•ˆì–‘ì‹œ", "ì²œì•ˆì‹œ", "ìš©ì¸ì‹œ",
        "ì„±ë‚¨ì‹œ", "ê³ ì–‘ì‹œ", "ë¶€ì²œì‹œ", "ì•ˆì‚°ì‹œ"
    ]

    def merge_sigungu(name):
        for city in merge_target_cities:
            if name.startswith(city):
                return city
        return name

    # âœ… ë³‘í•© ì ìš©
    df["ì‹œêµ°êµ¬"] = df["ì‹œêµ°êµ¬"].apply(merge_sigungu)

    # âœ… ì‹œêµ°êµ¬ ê¸°ì¤€ìœ¼ë¡œ ê·¸ë£¹í™”
    gungu_grouped = df.groupby("ì‹œêµ°êµ¬", as_index=False)["ê´€ê´‘ê°ìˆ˜"].sum()
    gungu_grouped["ë¹„ìœ¨"] = (gungu_grouped["ê´€ê´‘ê°ìˆ˜"] / total_visitors * 100)

    # âœ… ìƒìœ„ 20ê°œ ì¶”ì¶œ
    top20 = gungu_grouped.sort_values(by="ê´€ê´‘ê°ìˆ˜", ascending=False).head(20).reset_index(drop=True)

    # âœ… ê¸°íƒ€ ê³„ì‚°
    top20_total = top20["ê´€ê´‘ê°ìˆ˜"].sum()
    others_row = {
        "ì‹œêµ°êµ¬": "ê¸°íƒ€",
        "ê´€ê´‘ê°ìˆ˜": total_visitors - top20_total,
        "ë¹„ìœ¨": 100 - top20["ë¹„ìœ¨"].sum()
    }
    gungu_final = pd.concat([
        top20,
        pd.DataFrame([others_row]),
        pd.DataFrame([{
            "ì‹œêµ°êµ¬": "í•©ê³„",
            "ê´€ê´‘ê°ìˆ˜": total_visitors,
            "ë¹„ìœ¨": 100.0
        }])
    ], ignore_index=True)

    # âœ… ë¹„ìœ¨ í¬ë§·íŒ…
    gungu_final["ë¹„ìœ¨"] = gungu_final["ë¹„ìœ¨"].round(2).astype(str) + "%"

    # âœ… 2ì—´ ë¶„í• 
    mid = len(gungu_final) // 2 + len(gungu_final) % 2
    left = gungu_final.iloc[:mid].reset_index(drop=True)
    right = gungu_final.iloc[mid:].reset_index(drop=True)

    # âœ… ì ‘ë¯¸ì–´ë¡œ ì—´ ì¶©ëŒ ë°©ì§€
    left.columns = [f"{col}_1" for col in left.columns]
    right.columns = [f"{col}_2" for col in right.columns]
    result_gungu = pd.concat([left, right], axis=1)

    # âœ… ì‹œêµ°êµ¬ ë¶„ì„ ê²°ê³¼ ì¶œë ¥
    st.dataframe(result_gungu, use_container_width=True)

    # âœ… GPT ì‹œì‚¬ì  ìƒì„± (ì‹œë„ + ì‹œêµ°êµ¬ ê°ê°)
    with st.spinner("ğŸ¤– GPT ì‹œì‚¬ì  ìƒì„± ì¤‘..."):
        name = st.session_state.get("festival_name", "ë³¸ ì¶•ì œ")
        period = st.session_state.get("festival_period", "")
        location = st.session_state.get("festival_location", "")
        reference = load_insight_examples("7-1_visitor")

        # âœ… [1] ì‹œë„ë³„ ìš”ì•½ í…ìŠ¤íŠ¸
        grouped_summary = "\n".join([
            f"- {row['ì‹œë„']}: {int(row['ê´€ê´‘ê°ìˆ˜']):,}ëª… ({row['ë¹„ìœ¨']})"
            for _, row in grouped.iterrows()
        ])

        grouped_prompt = f"""ë‹¤ìŒì€ {name}({period}, {location}) ì¶•ì œì˜ ì‹œë„ë³„ ì™¸ì§€ì¸ ë°©ë¬¸ê° ë¶„ì„ì…ë‹ˆë‹¤.

[ì‹œë„ë³„ ì™¸ì§€ì¸ ë°©ë¬¸ê° ìˆ˜ ìš”ì•½]
{grouped_summary}

[ì°¸ê³ ìë£Œ]
{reference}

ìœ„ ë°ì´í„°ë¥¼ ë°”íƒ•ìœ¼ë¡œ, ì‹œë„ë³„ ë¶„í¬ì™€ íŠ¹ì§•ì„ í–‰ì • ë³´ê³ ì„œ ìŠ¤íƒ€ì¼ë¡œ 3~5ë¬¸ì¥ ì‘ì„±í•´ì£¼ì„¸ìš”.
"""

        grouped_response = client.chat.completions.create(
            model="gpt-4o",
            messages=[
                {"role": "system", "content": "ë„ˆëŠ” ì§€ë°©ì •ë¶€ ì¶•ì œ ë°ì´í„°ë¥¼ ë¶„ì„í•˜ëŠ” ì „ë¬¸ê°€ì•¼."},
                {"role": "user", "content": grouped_prompt}
            ],
            temperature=0.5,
            max_tokens=700
        )

        st.subheader("ğŸ§  GPT ì‹œì‚¬ì  (ì‹œë„ ê¸°ì¤€)")
        st.write(grouped_response.choices[0].message.content)

        # âœ… [2] ì‹œêµ°êµ¬ë³„ ìš”ì•½ í…ìŠ¤íŠ¸
        gungu_summary = "\n".join([
            f"- {row['ì‹œêµ°êµ¬']}: {int(row['ê´€ê´‘ê°ìˆ˜']):,}ëª… ({row['ë¹„ìœ¨']})"
            for _, row in gungu_final.iterrows() if row["ì‹œêµ°êµ¬"] not in ["ê¸°íƒ€", "í•©ê³„"]
        ])

        gungu_prompt = f"""ë‹¤ìŒì€ {name}({period}, {location}) ì¶•ì œì˜ ì‹œêµ°êµ¬ë³„ ì™¸ì§€ì¸ ë°©ë¬¸ê° ë¶„ì„ì…ë‹ˆë‹¤.

[ì‹œêµ°êµ¬ë³„ ì™¸ì§€ì¸ ë°©ë¬¸ê° ìˆ˜ ìš”ì•½]
{gungu_summary}

[ì°¸ê³ ìë£Œ]
{reference}

ìœ„ ë°ì´í„°ë¥¼ ë°”íƒ•ìœ¼ë¡œ, ì£¼ìš” ì‹œêµ°êµ¬ ë°©ë¬¸ ë¶„í¬ì™€ íŠ¹ì§•ì„ í–‰ì • ë³´ê³ ì„œ ìŠ¤íƒ€ì¼ë¡œ 3~5ë¬¸ì¥ ì‘ì„±í•´ì£¼ì„¸ìš”.
"""

        gungu_response = client.chat.completions.create(
            model="gpt-4o",
            messages=[
                {"role": "system", "content": "ë„ˆëŠ” ì§€ë°©ì •ë¶€ ì¶•ì œ ë°ì´í„°ë¥¼ ë¶„ì„í•˜ëŠ” ì „ë¬¸ê°€ì•¼."},
                {"role": "user", "content": gungu_prompt}
            ],
            temperature=0.5,
            max_tokens=700
        )

        st.subheader("ğŸ§  GPT ì‹œì‚¬ì  (ì‹œêµ°êµ¬ ê¸°ì¤€)")
        st.write(gungu_response.choices[0].message.content)

