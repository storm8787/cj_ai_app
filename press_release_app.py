#!/usr/bin/env python
# coding: utf-8

# In[10]:


import streamlit as st
from PyPDF2 import PdfReader
from sklearn.feature_extraction.text import TfidfVectorizer
from sklearn.metrics.pairwise import cosine_similarity
from openai import OpenAI
import os

# âœ… OpenAI API í‚¤ ì„¤ì •
#openai.api_key = st.secrets["OPENAI_API_KEY"]
client = OpenAI(api_key=st.secrets["OPENAI_API_KEY"])


# âœ… PDF í…ìŠ¤íŠ¸ ì¶”ì¶œ
def extract_text_from_pdf(file_obj):
    reader = PdfReader(file_obj)
    full_text = ""
    for page in reader.pages:
        page_text = page.extract_text()
        if page_text:
            full_text += page_text + "\n"
    return full_text

# âœ… ìœ ì‚¬ ë³´ë„ìë£Œ ê²€ìƒ‰
def find_similar_docs(query, documents, vectorizer, tfidf_matrix, top_n=3):
    query_vec = vectorizer.transform([query])
    similarity_scores = cosine_similarity(query_vec, tfidf_matrix).flatten()
    top_indices = similarity_scores.argsort()[::-1][:top_n]
    return [documents[i] for i in top_indices]

# âœ… ë³´ë„ìë£Œ ìƒì„±
def generate_press_release(user_request, similar_examples):
    system_prompt = "ë„ˆëŠ” ì§€ë°©ì •ë¶€ ë³´ë„ìë£Œ ì‘ì„± ì „ë¬¸ê°€ì•¼. ì•„ë˜ ìœ ì‚¬ ì‚¬ë¡€ë¥¼ ì°¸ê³ í•´, í–‰ì •ê¸°ê´€ ìŠ¤íƒ€ì¼ë¡œ ê³µê³µ ë³´ë„ìë£Œë¥¼ ì‘ì„±í•´ì¤˜."

    examples_combined = "\n\n---\n\n".join(similar_examples)
    joined_points = "\n- ".join(user_request['ë‚´ìš©í¬ì¸íŠ¸'])

    ê¸¸ì´ì§€ì‹œ = {
        "ì§§ê²Œ": 400,
        "ì¤‘ê°„": 600,
        "ê¸¸ê²Œ": 800
    }.get(user_request['ê¸¸ì´'], 600)

    ë¬¸ë‹¨ì§€ì‹œ = "" if user_request['ë¬¸ë‹¨ìˆ˜'] == "ìƒê´€ì—†ìŒ" else f"ì „ì²´ ê¸€ì€ {user_request['ë¬¸ë‹¨ìˆ˜']}ê°œì˜ ë¬¸ë‹¨ìœ¼ë¡œ êµ¬ì„±í•´ì£¼ì„¸ìš”.\n"

    ì¶”ê°€ì§€ì‹œ = (
        f"ë³´ë„ìë£Œì—ëŠ” ìƒë‹¨ì˜ ë³´ë„ì¼ì, ë‹´ë‹¹ì ì •ë³´, ì—°ë½ì²˜ëŠ” í¬í•¨í•˜ì§€ ë§ê³  ë³¸ë¬¸ë§Œ ì‘ì„±í•´ì£¼ì„¸ìš”.\n"
        f"ë‹´ë‹¹ì ì¸ìš©ë¬¸ì´ ë‚˜ì˜¬ ê²½ìš°, ë‹´ë‹¹ì ì´ë¦„ì€ '{user_request['ë‹´ë‹¹ì']}'ì´ê³ , ì§ì±…ì€ '{user_request['ë‹´ë‹¹ë¶€ì„œ']}ì¥'ìœ¼ë¡œ í‘œê¸°í•´ì£¼ì„¸ìš”.\n"
        f"ë‹´ë‹¹ì ì¸ìš©ë¬¸ì´ ë‚˜ì˜¬ ê²½ìš°, '{user_request['ë‹´ë‹¹ì']}' í•œì¹¸ë ê³ '{user_request['ë‹´ë‹¹ë¶€ì„œ']}ì¥'ìœ¼ë¡œ í‘œê¸°í•´ì£¼ì„¸ìš”.ex : ê¹€íƒœê·  ìì¹˜í–‰ì •ê³¼ì¥\n"
        f"ì „ì²´ ë¬¸ì²´ëŠ” ë³´ë„ìë£Œ ìŠ¤íƒ€ì¼ì˜ ê°„ì ‘í™”ë²•ì„ ì‚¬ìš©í•´ì£¼ì„¸ìš”. ì˜ˆ: '~í–ˆë‹¤', '~ë¼ê³  ë°í˜”ë‹¤' ë“±.\n"
        f"{ë¬¸ë‹¨ì§€ì‹œ}"
        f"ë³´ë„ìë£ŒëŠ” ë°˜ë“œì‹œ '[ì œëª©] ë³¸ë¬¸ì œëª©'ìœ¼ë¡œ ì‹œì‘í•œ í›„, í•œ ì¤„ ì•„ë˜ì— ë¶€ì œëª© í˜•íƒœì˜ ìš”ì•½ ë¬¸ì¥ì„ ë„£ì–´ì£¼ì„¸ìš”. ë¶€ì œëª©ì€ '-' ê¸°í˜¸ë¡œ ì‹œì‘í•˜ì„¸ìš”.\n"
        f"ì „ì²´ ë³´ë„ìë£Œ ë¶„ëŸ‰ì€ ì•½ {ê¸¸ì´ì§€ì‹œ}ì ë‚´ì™¸ë¡œ ì‘ì„±í•´ì£¼ì„¸ìš”. í•„ìš” ì‹œ ìµœëŒ€ í† í° ìˆ˜ë¥¼ ëŠ˜ë ¤ë„ ê´œì°®ìŠµë‹ˆë‹¤."
        f"ì „ì²´ ë³´ë„ìë£ŒëŠ” ë°˜ë“œì‹œ {ê¸¸ì´ì§€ì‹œ}ì ì•ˆíŒ(Â±10ì ì´ë‚´)ë¡œ ì‘ì„±í•´ì£¼ì„¸ìš”."

    )

    user_query_prompt = (
        f"ì…ë ¥í•œ ì œëª© í›„ë³´: {user_request['ì œëª©']}\n\n"
        f"ì•„ë˜ ë‚´ìš© í¬ì¸íŠ¸ë¥¼ ë°˜ì˜í•˜ì—¬ ë³´ë„ìë£Œì— ì–´ìš¸ë¦¬ëŠ” ì œëª©ì„ ìƒˆë¡œ ì‘ì„±í•˜ê³ , "
        f"ê·¸ ì œëª©ì„ '[ì œëª©]'ì— ë°˜ì˜í•´ì¤˜. ì…ë ¥í•œ ì œëª©ì€ ì°¸ê³ ë§Œ í•˜ê³  ê·¸ëŒ€ë¡œ ì“°ì§€ ì•Šì•„ë„ ë¼.\n\n"
        f"ë‚´ìš© í¬ì¸íŠ¸:\n- {joined_points}\n\n"
        f"ìš”ì²­ì‚¬í•­:\n- {user_request['ê¸°íƒ€ìš”ì²­']}\n\n"
        f"{ì¶”ê°€ì§€ì‹œ}"
    )

    messages = [
        {"role": "system", "content": system_prompt},
        {"role": "user", "content": f"""ì•„ë˜ëŠ” ì°¸ê³ ìš© ë³´ë„ìë£Œ ì˜ˆì‹œì…ë‹ˆë‹¤:

{examples_combined}

ìœ„ ìŠ¤íƒ€ì¼ì„ ì°¸ê³ í•˜ì—¬ ì•„ë˜ ìš”ì²­ì‚¬í•­ì— ë§ëŠ” ìƒˆë¡œìš´ ë³´ë„ìë£Œë¥¼ ì‘ì„±í•´ì¤˜:

{user_query_prompt}
"""}
    ]

    client = OpenAI(api_key=st.secrets["OPENAI_API_KEY"])  # í‚¤ëŠ” secretsì—ì„œ ë¶ˆëŸ¬ì˜¨ë‹¤ê³  ê°€ì •

    response = client.chat.completions.create(
        model="gpt-4o",
        messages=messages,
        temperature=0.5,
        max_tokens=1500
    )

    return response.choices[0].message.content

# âœ… Streamlit ì•± ì‹œì‘
st.title("ğŸ“° GPT ê¸°ë°˜ ë³´ë„ìë£Œ ìë™ ìƒì„±ê¸°")

# ğŸ“‚ corpus.txt ìë™ ë¡œë”©
txt_path = "data/corpus.txt"
if os.path.exists(txt_path):
    with open(txt_path, "r", encoding="utf-8") as f:
        corpus_text = f.read()
    documents = [doc.strip() for doc in corpus_text.split("---") if len(doc.strip()) > 50]
    if not documents:
        st.error("âŒ corpus.txtì—ì„œ ìœ íš¨í•œ ë³´ë„ìë£Œë¥¼ ì¶”ì¶œí•˜ì§€ ëª»í–ˆìŠµë‹ˆë‹¤.")
else:
    st.error(f"âŒ í…ìŠ¤íŠ¸ íŒŒì¼ì„ ì°¾ì„ ìˆ˜ ì—†ìŠµë‹ˆë‹¤: {txt_path}")
    st.stop()


# ğŸ“¥ ì‚¬ìš©ì ì…ë ¥ê°’ ìˆ˜ì§‘
ì œëª© = st.text_input("ğŸ“ ë³´ë„ìë£Œ ì œëª©ì„ ì…ë ¥í•˜ì„¸ìš”")
ë‹´ë‹¹ë¶€ì„œ = st.text_input("ğŸ¢ ë‹´ë‹¹ ë¶€ì„œëª…ì„ ì…ë ¥í•˜ì„¸ìš”")
ë‹´ë‹¹ì = st.text_input("ğŸ§‘â€ğŸ« ë‹´ë‹¹ì ì´ë¦„ì„ ì…ë ¥í•˜ì„¸ìš”")

ë¬¸ë‹¨ìˆ˜ = st.selectbox("ğŸ“‘ ë¬¸ë‹¨ ìˆ˜ë¥¼ ì„ íƒí•˜ì„¸ìš”", ["ìƒê´€ì—†ìŒ", "1ê°œ", "2ê°œ", "3ê°œ"])
ê¸¸ì´ = st.selectbox("ğŸ“ ë³´ë„ìë£Œ ê¸¸ì´", ["ì§§ê²Œ", "ì¤‘ê°„", "ê¸¸ê²Œ"])  # 400, 600, 800ì
ë‚´ìš©í¬ì¸íŠ¸ = st.text_area("ğŸ“Œ ë‚´ìš© í¬ì¸íŠ¸ (í•œ ì¤„ì— í•˜ë‚˜ì”© ì…ë ¥)", height=150)
ê¸°íƒ€ìš”ì²­ = st.text_area("ğŸ”§ ê¸°íƒ€ ìš”ì²­ì‚¬í•­", height=100)


# âœ… ì‹¤í–‰ ë²„íŠ¼
if st.button("ğŸš€ ë³´ë„ìë£Œ ìƒì„±í•˜ê¸°"):
    if ì œëª© and ë‚´ìš©í¬ì¸íŠ¸:
        user_request = {
            "ì œëª©": ì œëª©,
            "ë‚´ìš©í¬ì¸íŠ¸": [line.strip() for line in ë‚´ìš©í¬ì¸íŠ¸.strip().split("\n") if line.strip()],
            "ê¸°íƒ€ìš”ì²­": ê¸°íƒ€ìš”ì²­.strip(),
            "ë‹´ë‹¹ë¶€ì„œ": ë‹´ë‹¹ë¶€ì„œ.strip(),
            "ë‹´ë‹¹ì": ë‹´ë‹¹ì.strip(),
            "ë¬¸ë‹¨ìˆ˜": ë¬¸ë‹¨ìˆ˜,
            "ê¸¸ì´": ê¸¸ì´
        }

        vectorizer = TfidfVectorizer()
        tfidf_matrix = vectorizer.fit_transform(documents)
        similar_examples = find_similar_docs(ì œëª©, documents, vectorizer, tfidf_matrix)

        with st.spinner("ğŸ¤– GPTê°€ ë³´ë„ìë£Œë¥¼ ì‘ì„± ì¤‘ì…ë‹ˆë‹¤..."):
            press_release = generate_press_release(user_request, similar_examples)
            st.success("âœ… ë³´ë„ìë£Œê°€ ìƒì„±ë˜ì—ˆìŠµë‹ˆë‹¤!")
            st.text_area("ğŸ“„ ìƒì„±ëœ ë³´ë„ìë£Œ", press_release, height=500)
    else:
        st.warning("âš ï¸ ì œëª©ê³¼ ë‚´ìš© í¬ì¸íŠ¸ëŠ” ë°˜ë“œì‹œ ì…ë ¥í•´ì•¼ í•©ë‹ˆë‹¤.")


# In[ ]:




